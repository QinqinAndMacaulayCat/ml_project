{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "63a56e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e62d792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hw/dfkspcjj1bv53cx3_42lwrtc0000gn/T/ipykernel_25353/1798892931.py:3: DtypeWarning: Columns (55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_temp = pd.read_csv(f\"../data/raw/wrds_bond_returns{i}.csv.gz\", compression=\"gzip\")\n",
      "/var/folders/hw/dfkspcjj1bv53cx3_42lwrtc0000gn/T/ipykernel_25353/1798892931.py:3: DtypeWarning: Columns (55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_temp = pd.read_csv(f\"../data/raw/wrds_bond_returns{i}.csv.gz\", compression=\"gzip\")\n",
      "/var/folders/hw/dfkspcjj1bv53cx3_42lwrtc0000gn/T/ipykernel_25353/1798892931.py:3: DtypeWarning: Columns (15,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_temp = pd.read_csv(f\"../data/raw/wrds_bond_returns{i}.csv.gz\", compression=\"gzip\")\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.DataFrame()\n",
    "for i in range(1, 6):\n",
    "    df_temp = pd.read_csv(f\"../data/raw/wrds_bond_returns{i}.csv.gz\", compression=\"gzip\")\n",
    "    raw_data = pd.concat([raw_data, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ff5dbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data.copy()\n",
    "# Lowercase column names\n",
    "cols = [str_.lower() for str_ in df.columns]\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "56ff77a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'issue_id', 'cusip', 'bond_sym_id', 'bsym', 'isin', 'company_symbol', 'bond_type', 'security_level', 'conv', 'offering_date', 'offering_amt', 'offering_price', 'principal_amt', 'maturity', 'treasury_maturity', 'coupon', 'day_count_basis', 'dated_date', 'first_interest_date', 'last_interest_date', 'ncoups', 'amount_outstanding', 'r_sp', 'r_mr', 'r_fr', 'n_sp', 'n_mr', 'n_fr', 'rating_num', 'rating_cat', 'rating_class', 't_date', 't_volume', 't_dvolume', 't_spread', 't_yld_pt', 'yield', 'price_eom', 'price_ldm', 'price_l5m', 'gap', 'coupmonth', 'nextcoup', 'coupamt', 'coupacc', 'multicoups', 'ret_eom', 'ret_ldm', 'ret_l5m', 'tmt', 'remcoups', 'duration', 'defaulted', 'default_date', 'default_type', 'reinstated', 'reinstated_date']\n"
     ]
    }
   ],
   "source": [
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6433be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial shape: (3854028, 58)\n",
      "after removing defaulted bonds: (3840829, 58)\n",
      "after keeping only senior bonds: (3567979, 58)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter bond types\n",
    "print(\"initial shape:\", df.shape)\n",
    "# Delete defaulted bonds\n",
    "df = df[df['defaulted']=='N']\n",
    "print(\"after removing defaulted bonds:\", df.shape)\n",
    "\n",
    "# Keep only senior bonds\n",
    "df = df[df['security_level'] == 'SEN']\n",
    "print(\"after keeping only senior bonds:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2e14b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "select_cols = ['date', \n",
    "               'cusip', # CUSIP identifier\n",
    "               'company_symbol', # Company ticker symbol\n",
    "               'tmt', # Time to Maturity\n",
    "               'coupon', # Coupon Rate\n",
    "               't_spread', # Average bid-ask spread\n",
    "               'yield', # Yield to Maturity\n",
    "               'ret_eom', # Total Return End of Month (Including Coupons)\n",
    "               'rating_cat', # Weighted Average Rating Category\n",
    "]\n",
    "df = df[select_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "26853070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate found, use (date, cusip) as unique identifier.\n"
     ]
    }
   ],
   "source": [
    "# Check if there is duplicate keys\n",
    "if df.duplicated(subset=['date', 'cusip']).sum() > 0:\n",
    "    print(\"Warning: There are duplicate keys in the data!\")\n",
    "else:\n",
    "    print(\"No duplicate found, use (date, cusip) as unique identifier.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b15d3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data types\n",
    "df.loc[:, ['tmt', 'coupon']] = df.loc[:, ['tmt', 'coupon']].astype(float) \n",
    "df.loc[:, 'coupon'] = df.loc[:, 'coupon'] / 100.0  # convert coupon to decimal\n",
    "\n",
    "for col in ['t_spread', 'yield', 'ret_eom']:\n",
    "    df[col] = df[col].str.rstrip('%').astype(float) / 100.0\n",
    "\n",
    "df.loc[:, ['t_spread', 'yield', 'ret_eom']] = df.loc[:, ['t_spread', 'yield', 'ret_eom']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "509f417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with anomalies\n",
    "\n",
    "# extreme yields\n",
    "df.loc[df['yield'] > 1, 'yield'] = float('nan')  # yields greater than 200% as high yield bonds should have different logic\n",
    "df.loc[df['yield'] < -1, 'yield'] = float('nan')  # yields less than -100% are likely data errors\n",
    "\n",
    "# fill nan ratings with 'NR' (not rated)\n",
    "df['rating_cat'] = df['rating_cat'].fillna('NR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fd010ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot coding for rating_cat\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "oh = OneHotEncoder()\n",
    "rating_cat_oh = oh.fit_transform(df[['rating_cat']]).toarray()\n",
    "rating_cat_oh_df = pd.DataFrame(rating_cat_oh, columns=[f\"rating_{cat}\" for cat in oh.categories_[0]]).astype(int)\n",
    "df = pd.concat([df.reset_index(drop=True), rating_cat_oh_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Delete NR category as it does not provide useful information\n",
    "df = df.drop(columns=['rating_NR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "16e33ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dict = {'AAA': 1,\n",
    "               'AA': 2,\n",
    "               'A': 3,\n",
    "               'BBB': 4,\n",
    "               'BB': 5,\n",
    "               'B': 6,\n",
    "               'CCC': 7,\n",
    "               'CC': 8,\n",
    "               'C': 9,\n",
    "               'D': 10,\n",
    "               'NR': float('nan')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3492f766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hw/dfkspcjj1bv53cx3_42lwrtc0000gn/T/ipykernel_25353/1010259344.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 0 0 ... 0 0 0]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, ['upgrade', 'downgrade']] = df.loc[:, ['upgrade', 'downgrade']].fillna(0).astype(int)\n",
      "/var/folders/hw/dfkspcjj1bv53cx3_42lwrtc0000gn/T/ipykernel_25353/1010259344.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 0 0 ... 0 0 0]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, ['upgrade', 'downgrade']] = df.loc[:, ['upgrade', 'downgrade']].fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Find rating downgrades and upgrades\n",
    "df = df.sort_values(by=['cusip', 'date'])\n",
    "df.loc[:, 'upgrade'] = df.groupby('cusip')['rating_cat'].transform(lambda x: x.map(rating_dict).diff() < 0)\n",
    "df.loc[:, 'downgrade'] = df.groupby('cusip')['rating_cat'].transform(lambda x: x.map(rating_dict).diff() > 0)\n",
    "\n",
    "# Fill NaN values in upgrade and downgrade columns with 0\n",
    "df.loc[:, ['upgrade', 'downgrade']] = df.loc[:, ['upgrade', 'downgrade']].fillna(0).astype(int)\n",
    "\n",
    "# Delete rating_cat column\n",
    "df = df.drop(columns=['rating_cat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1da783aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date column to datetime and use the end of month\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y%m%d') + pd.offsets.MonthEnd(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e051d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Interest Rate Data\n",
    "ir_raw_data = pd.read_csv(\"../data/raw/interest_rate.csv.gz\", compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1eb9be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Treasury Constant Maturity 3-Month Rate as short-term interest rate and 10-Year Rate as long-term interest rate\n",
    "ir_data = ir_raw_data[['date', 'gs3m', 'gs10']].copy()\n",
    "ir_data.loc[:, ['gs3m', 'gs10']] = ir_data.loc[:, ['gs3m', 'gs10']] / 100.0  # convert to decimal\n",
    "ir_data.loc[:, 'term_spread'] = ir_data['gs10'] - ir_data['gs3m']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3f09bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date column to datetime and use the end of month\n",
    "ir_data['date'] = pd.to_datetime(ir_data['date'], format='%Y-%m-%d') + pd.offsets.MonthEnd(0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2fee7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge interest rate data with bond data\n",
    "df = pd.merge(df, ir_data[['date', 'gs3m', 'term_spread']], on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift predictor variables by 1 month to avoid look-ahead bias\n",
    "constant_cols = ['date', 'cusip', 'company_symbol', 'tmt', 'coupon', 'ret_eom']\n",
    "lagged_cols = df.columns.difference(constant_cols)\n",
    "df.sort_values(by=['cusip', 'date'], inplace=True)\n",
    "df[lagged_cols] = df.groupby('cusip')[lagged_cols].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7f93a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7e0b18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/processed/bond_data_processed.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5638ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.describe()\n",
    "summary.to_csv(\"../data/processed/bond_data_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a8931189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN summary:\n",
      "date              0.000000\n",
      "cusip             0.000000\n",
      "company_symbol    0.000189\n",
      "tmt               0.002783\n",
      "coupon            0.000886\n",
      "t_spread          0.499684\n",
      "yield             0.050220\n",
      "ret_eom           0.040485\n",
      "rating_A          0.040469\n",
      "rating_AA         0.040469\n",
      "rating_AAA        0.040469\n",
      "rating_B          0.040469\n",
      "rating_BB         0.040469\n",
      "rating_BBB        0.040469\n",
      "rating_C          0.040469\n",
      "rating_CC         0.040469\n",
      "rating_CCC        0.040469\n",
      "rating_D          0.040469\n",
      "upgrade           0.040469\n",
      "downgrade         0.040469\n",
      "gs3m              0.040469\n",
      "term_spread       0.040469\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# NaN check\n",
    "nan_summary = df.isna().sum()\n",
    "print(\"NaN summary:\")\n",
    "print(nan_summary / len(df))  # percentage of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "51b1429a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760852\n",
      "74191\n",
      "3187\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df['cusip'].nunique())\n",
    "print(df['company_symbol'].nunique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
